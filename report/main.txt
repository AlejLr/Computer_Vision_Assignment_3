First important decisions discussion:

In this project, our objective is to build and compare gesture recognition models under realistic computational constraints. All experiments were conducted using the university’s standard hardware resources, specifically machines equipped with an Intel Core i7-14700 CPU, 32 GB RAM, and an NVIDIA GeForce RTX 4060 GPU with 8 GB of VRAM. Based on these resource limitations, we formulated a constraint guiding our entire design:

Constraint: We aim to maximize gesture recognition accuracy while ensuring that each experiment remains feasible on a single 8 GB GPU, with a total training time of approximately 2–3 hours per run.

To explore how different modelling choices behave under this constraint, we designed three models of increasing complexity:

Baseline model (2D CNN, single frame):
A simple and computationally efficient model using a pretrained ResNet-18. Each video is represented only by its center frame, resized to 224×224, and the entire network is fine-tuned on the Jester dataset. This model establishes a lower bound on performance and provides a transparent reference point for comparison.

Improved model (2D CNN with temporal modelling):
A multi-frame approach using a shared 2D backbone applied to uniformly sampled frames, combined with a temporal aggregation module (e.g., recurrent or attention-based). This design introduces explicit temporal reasoning while remaining lightweight enough to satisfy the 8 GB compute budget.

Heavy model (beyond constraint):
A more computationally demanding architecture, such as a 3D convolutional network, designed to exceed our hardware limitations. This model is included to highlight the trade-offs between performance and practicality, and to demonstrate how larger architectures quickly violate our training-time and VRAM constraints.

To support efficient experimentation under these constraints, we initially train and debug using the 20% subset of the Jester training set while always evaluating on the complete validation set. Once models are stable, we optionally scale training to the full dataset when feasible.

Regarding data handling, we preserve the original video files and perform on-the-fly decoding using parallel DataLoader workers. This approach reduces disk usage and maintains flexibility during development. Pre-decoding frames was considered but rejected initially due to its large storage footprint (~100–250 GB) and limited impact on early prototyping. This choice aligns with our compute constraint: decoding overhead proved minor relative to training time on the target hardware.

The baseline uses deterministic center-frame sampling, which simplifies analysis by intentionally removing temporal information. This choice makes the performance gap between the baseline and temporal model clearer and easier to interpret. Multi-frame sampling and temporal augmentation are introduced only in the improved model, consistent with its purpose.

Experiment execution is performed through reproducible Python scripts run on university servers or lab machines. Jupyter notebooks are used only for exploratory analysis and visualization. All code development is done locally and synchronized via GitHub, with a unified conda environment and YAML-based configuration system ensuring consistency across devices and operating systems.

Together, these decisions create a coherent methodology that closely ties modelling choices to computational constraints while enabling a meaningful comparison between simple, optimized, and computationally expensive gesture recognition architectures.

